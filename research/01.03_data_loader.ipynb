{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T16:57:23.112015Z",
     "start_time": "2025-04-21T16:57:23.098411Z"
    }
   },
   "source": "import os",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:57:39.934140Z",
     "start_time": "2025-04-21T16:57:39.917134Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "b29584a66ffdd94f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DIKSHANT PATEL\\\\Kidney-Disease-Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:57:52.134276Z",
     "start_time": "2025-04-21T16:57:52.122278Z"
    }
   },
   "cell_type": "code",
   "source": "os.chdir(\"../.\")",
   "id": "5ff8ac6f33a3573d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T16:57:56.825792Z",
     "start_time": "2025-04-21T16:57:56.813791Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "68610b95d07c3f45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DIKSHANT PATEL\\\\Kidney-Disease-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:42:18.054745Z",
     "start_time": "2025-04-21T17:42:18.041576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataLoaderConfig:\n",
    "    root_dir: str\n",
    "    train_data: str\n",
    "    valid_data: str\n",
    "    test_data: str\n",
    "    target_size: tuple\n",
    "    batch_size: int\n",
    "    color_mode: str\n",
    "    class_mode: str\n",
    "    seed: int\n",
    "    rotation_range: int\n",
    "    width_shift_range: float\n",
    "    height_shift_range: float\n",
    "    shear_range: float\n",
    "    zoom_range: float\n",
    "    horizontal_flip: bool\n",
    "    fill_mode: str"
   ],
   "id": "440b17550e6007f9",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:42:18.349269Z",
     "start_time": "2025-04-21T17:42:18.335233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ],
   "id": "1f529468020e87a8",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T17:42:18.646378Z",
     "start_time": "2025-04-21T17:42:18.632347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath = CONFIG_FILE_PATH, params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "    def get_data_loader_config(self) -> DataLoaderConfig:\n",
    "        config = self.config.data_loader\n",
    "        params = self.params.data_loader\n",
    "        return DataLoaderConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data=config.train_data,\n",
    "            valid_data=config.valid_data,\n",
    "            test_data=config.test_data,\n",
    "            target_size=params.target_size,\n",
    "            batch_size=params.batch_size,\n",
    "            color_mode=params.color_mode,\n",
    "            class_mode=params.class_mode,\n",
    "            seed=params.seed,\n",
    "            rotation_range=params.rotation_range,\n",
    "            width_shift_range=params.width_shift_range,\n",
    "            height_shift_range=params.height_shift_range,\n",
    "            shear_range=params.shear_range,\n",
    "            zoom_range=params.zoom_range,\n",
    "            horizontal_flip=params.horizontal_flip,\n",
    "            fill_mode = params.fill_mode\n",
    "        )\n",
    "        "
   ],
   "id": "7f60c6dac3c6e5d1",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T18:04:50.675167Z",
     "start_time": "2025-04-21T18:04:50.660145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from cnnClassifier import logger"
   ],
   "id": "f5f9004cce89d18c",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T18:04:50.926980Z",
     "start_time": "2025-04-21T18:04:50.907982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataLoader: \n",
    "    def __init__(self, config: DataLoaderConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def create_generator(self):\n",
    "        aug = ImageDataGenerator(\n",
    "            rescale=1.0 / 255,\n",
    "            rotation_range=self.config.rotation_range,\n",
    "            width_shift_range=self.config.width_shift_range,\n",
    "            height_shift_range=self.config.height_shift_range,\n",
    "            shear_range=self.config.shear_range,\n",
    "            zoom_range=self.config.zoom_range,\n",
    "            horizontal_flip=self.config.horizontal_flip,\n",
    "            fill_mode=self.config.fill_mode,\n",
    "        )\n",
    "        ori = ImageDataGenerator(rescale=1.0 / 255)\n",
    "        logger.info(\"Generators created successfully.\")\n",
    "        return aug, ori\n",
    "    \n",
    "    def load_dataframe(self, file_path):\n",
    "        logger.info(f\"Loading dataframe from file: {file_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            logger.info(f\"Dataframe loaded successfully with {len(df)} records.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading dataframe from {file_path}: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "    def get_flow(self,df,generator, shuffle = True):\n",
    "         return generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            x_col=\"filepath\",        \n",
    "            y_col=\"label\",            \n",
    "            target_size=tuple(self.config.target_size),  \n",
    "            batch_size=self.config.batch_size,  \n",
    "            class_mode=self.config.class_mode, \n",
    "            color_mode=self.config.color_mode,  \n",
    "            shuffle=shuffle,  \n",
    "            seed=self.config.seed  \n",
    "        )\n",
    "    def combined_generator(self, aug, ori):\n",
    "        # Combines augmented and original data\n",
    "        logger.info(f\"Combining augmented and original data generators.\")\n",
    "        n_orig = int(0.5 * len(aug))  \n",
    "        n_aug = len(aug) - n_orig \n",
    "\n",
    "        while True:\n",
    "            aug_images, aug_labels = next(aug)\n",
    "            ori_images, ori_labels = next(ori)\n",
    "\n",
    "            # Combine the two datasets\n",
    "            images = np.concatenate((ori_images[:n_orig], aug_images[n_aug:]), axis=0)\n",
    "            labels = np.concatenate((ori_labels[:n_orig], aug_labels[n_aug:]), axis=0)\n",
    "\n",
    "            yield images, labels\n",
    "    \n",
    "    def get_generators(self):\n",
    "        # File paths for the CSVs\n",
    "        train_path = f\"{self.config.root_dir}/{self.config.train_data}\"\n",
    "        valid_path = f\"{self.config.root_dir}/{self.config.valid_data}\"\n",
    "        test_path = f\"{self.config.root_dir}/{self.config.test_data}\"\n",
    "\n",
    "        # Load the dataframes\n",
    "        try:\n",
    "            train_df = self.load_dataframe(train_path)\n",
    "            valid_df = self.load_dataframe(valid_path)\n",
    "            test_df = self.load_dataframe(test_path)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading dataframes: {str(e)}\")\n",
    "            raise e\n",
    "        train_df['label'] = train_df['label'].astype(str)\n",
    "        test_df['label'] = test_df['label'].astype(str)\n",
    "        valid_df['label'] = valid_df['label'].astype(str)\n",
    "        # Create generators\n",
    "        aug_gen, ori_gen = self.create_generator()\n",
    "\n",
    "        # Get augmented and original image generators\n",
    "        aug_train = self.get_flow(train_df, aug_gen, shuffle=True)\n",
    "        ori_train = self.get_flow(train_df, ori_gen, shuffle=True)\n",
    "\n",
    "\n",
    "        train = self.combined_generator(aug_train, ori_train)\n",
    "        valid = self.get_flow(valid_df, ori_gen, shuffle=False)\n",
    "        test = self.get_flow(test_df, ori_gen, shuffle=False)\n",
    "        logger.info(f\"Successfully Create the train:{train} validation: {valid} and test: {test} generators.\")\n",
    "        return train, valid, test\n",
    "        "
   ],
   "id": "ae5edaa0a075f37d",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T18:04:52.935191Z",
     "start_time": "2025-04-21T18:04:51.379428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    \n",
    "    config = ConfigurationManager()\n",
    "    data_loader_config = config.get_data_loader_config()\n",
    "    data_loader = DataLoader(config=data_loader_config)\n",
    "    train_generator, valid_generator, test_generator = data_loader.get_generators()\n",
    "\n",
    "except Exception as e:\n",
    "    raise e"
   ],
   "id": "9580346885e19849",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-21 20:04:51,386: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-04-21 20:04:51,390: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-04-21 20:04:51,392: INFO: 638489892: Loading dataframe from file: artifacts/data_split/train.csv]\n",
      "[2025-04-21 20:04:51,414: INFO: 638489892: Dataframe loaded successfully with 8712 records.]\n",
      "[2025-04-21 20:04:51,415: INFO: 638489892: Loading dataframe from file: artifacts/data_split/val.csv]\n",
      "[2025-04-21 20:04:51,420: INFO: 638489892: Dataframe loaded successfully with 1121 records.]\n",
      "[2025-04-21 20:04:51,421: INFO: 638489892: Loading dataframe from file: artifacts/data_split/test.csv]\n",
      "[2025-04-21 20:04:51,432: INFO: 638489892: Dataframe loaded successfully with 2613 records.]\n",
      "[2025-04-21 20:04:51,438: INFO: 638489892: Generators created successfully.]\n",
      "Found 8712 validated image filenames belonging to 4 classes.\n",
      "Found 8712 validated image filenames belonging to 4 classes.\n",
      "[2025-04-21 20:04:52,712: INFO: 638489892:  Successfully Create the training generator (augmented and original).]\n",
      "Found 1121 validated image filenames belonging to 4 classes.\n",
      "Found 2613 validated image filenames belonging to 4 classes.\n",
      "[2025-04-21 20:04:52,917: INFO: 638489892: Successfully Create the validation and test generators.]\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "89bd61aa96befeb4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
