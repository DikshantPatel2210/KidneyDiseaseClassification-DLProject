{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:36.320971Z",
     "start_time": "2025-05-13T08:07:36.312949Z"
    }
   },
   "source": "import os",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:36.572171Z",
     "start_time": "2025-05-13T08:07:36.560170Z"
    }
   },
   "cell_type": "code",
   "source": "os.getcwd()",
   "id": "bda127de225618f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DIKSHANT PATEL\\\\Kidney-Disease-Classification\\\\research'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:37.180833Z",
     "start_time": "2025-05-13T08:07:37.172833Z"
    }
   },
   "cell_type": "code",
   "source": "os.chdir('./..')",
   "id": "a6e52d1ae4fe201",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:37.427863Z",
     "start_time": "2025-05-13T08:07:37.420862Z"
    }
   },
   "cell_type": "code",
   "source": "%pwd",
   "id": "c5e27eeb50cd63e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DIKSHANT PATEL\\\\Kidney-Disease-Classification'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:37.721299Z",
     "start_time": "2025-05-13T08:07:37.701243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen = True)\n",
    "class OptunaConfig:\n",
    "      min_n_conv_layers: int\n",
    "      max_n_conv_layers: int\n",
    "      min_n_dense_layers: int\n",
    "      max_n_dense_layers: int\n",
    "      optimizer: list\n",
    "      Conv2D_strides_size: list\n",
    "      MaxPooling2D_strides_size: list\n",
    "      filters: list\n",
    "      dense_units: list\n",
    "      Conv2D_kernel_size: list\n",
    "      MaxPooling2D_kernel_size: list\n",
    "      activation: list\n",
    "      metrics: list\n",
    "      epochs: int\n",
    "      loss: str\n",
    "      "
   ],
   "id": "8e1818804572f08",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:38.155872Z",
     "start_time": "2025-05-13T08:07:38.008907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ],
   "id": "a88a54e35ee64bb5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:38.331158Z",
     "start_time": "2025-05-13T08:07:38.323156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "    def get_Optuna_config(self) -> OptunaConfig:\n",
    "        \n",
    "        Optuna_params = self.params.Optuna_tuning\n",
    "        \n",
    "        return OptunaConfig(\n",
    "            min_n_conv_layers = Optuna_params.min_n_conv_layers,\n",
    "            max_n_conv_layers= Optuna_params.max_n_conv_layers,\n",
    "            min_n_dense_layers= Optuna_params.min_n_dense_layers,\n",
    "            max_n_dense_layers= Optuna_params.max_n_dense_layers,\n",
    "            optimizer= Optuna_params.optimizer,\n",
    "            Conv2D_strides_size= Optuna_params.Conv2D_strides_size,\n",
    "            MaxPooling2D_strides_size= Optuna_params.MaxPooling2D_strides_size,\n",
    "            filters= Optuna_params.filters,\n",
    "            dense_units= Optuna_params.dense_units,\n",
    "            Conv2D_kernel_size= Optuna_params.Conv2D_kernel_size,\n",
    "            MaxPooling2D_kernel_size = Optuna_params.MaxPooling2D_kernel_size,\n",
    "            activation= Optuna_params.activation,\n",
    "            metrics= Optuna_params.metrics,\n",
    "            epochs= Optuna_params.epochs,\n",
    "            loss= Optuna_params.loss,\n",
    "        \n",
    "        )\n",
    "        "
   ],
   "id": "586ce4b0d059218d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:43.171822Z",
     "start_time": "2025-05-13T08:07:39.227947Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install optuna-integration",
   "id": "466354fa272c084b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna-integration in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: optuna in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna-integration) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (23.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (6.0.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (1.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (1.26.4)\n",
      "Requirement already satisfied: colorlog in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (6.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (4.67.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from optuna->optuna-integration) (2.0.40)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration) (4.12.2)\n",
      "Requirement already satisfied: Mako in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna->optuna-integration) (1.3.9)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from colorlog->optuna->optuna-integration) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\dikshant patel\\kidney-disease-classification\\.venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\DIKSHANT PATEL\\Kidney-Disease-Classification\\.venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:48.775215Z",
     "start_time": "2025-05-13T08:07:44.234823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from tensorflow.keras.layers import(\n",
    "Conv2D, MaxPooling2D, Dense, Dropout,BatchNormalization, GlobalAveragePooling2D)\n",
    "\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau)\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "import optuna\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n",
    "from cnnClassifier import logger\n",
    "from mlflow.models import infer_signature\n",
    "import dagshub\n"
   ],
   "id": "248706bcf60031a8",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:49.039887Z",
     "start_time": "2025-05-13T08:07:48.777009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tensorflow.keras import backend as K"
   ],
   "id": "33844ed245befaac",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T08:07:49.054582Z",
     "start_time": "2025-05-13T08:07:49.040887Z"
    }
   },
   "cell_type": "code",
   "source": "from optuna.samplers import TPESampler",
   "id": "40440b488842b988",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T09:16:42.574109Z",
     "start_time": "2025-05-13T09:16:42.533076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OptunaModelTunner11:\n",
    "    def __init__(self,params: OptunaConfig, training_set, validation_set, train_df, callbacks, class_weights_dict, class_names):\n",
    "        self.params = params\n",
    "        self.training_set = training_set\n",
    "        self.validation_set = validation_set\n",
    "        self.train_df = train_df\n",
    "        self.callbacks = callbacks\n",
    "        self.class_weights_dict = class_weights_dict\n",
    "        self.class_names = class_names\n",
    "        \n",
    "    def create_model(self, trial):\n",
    "        n_conv_layers = trial.suggest_int(\"n_conv_layers\", self.params.min_n_conv_layers, self.params.max_n_conv_layers)\n",
    "        n_dense_layers = trial.suggest_int(\"n_dense_layers\", self.params.min_n_dense_layers, self.params.max_n_dense_layers)\n",
    "        optimizer_name = trial.suggest_categorical('optimizer', self.params.optimizer)\n",
    "        Conv2D_strides_size = trial.suggest_categorical(\"Conv2D_strides_size\",self.params.Conv2D_strides_size) \n",
    "        Conv2D_stride = tuple(map(int, Conv2D_strides_size.lower().split(\"x\")))\n",
    "        \n",
    "        Conv2D_kernel_size_str = trial.suggest_categorical(\"Conv2D_kernel_size\", self.params.Conv2D_kernel_size)\n",
    "        Conv2D_kernel_size = tuple(map(int, Conv2D_kernel_size_str.lower().split(\"x\")))\n",
    "        \n",
    "        \n",
    "        MaxPooling2D_strides_size = trial.suggest_categorical(\"MaxPooling2D_strides_size\",self.params.MaxPooling2D_strides_size) \n",
    "        MaxPooling2D_stride = tuple(map(int, MaxPooling2D_strides_size.lower().split(\"x\")))\n",
    "        \n",
    "        MaxPooling2D_kernel_size_str = trial.suggest_categorical(\"MaxPooling2D_kernel_size\", self.params.MaxPooling2D_kernel_size)\n",
    "        MaxPooling2D_kernel_size = tuple(map(int, MaxPooling2D_kernel_size_str.lower().split(\"x\")))\n",
    "        \n",
    "     \n",
    "        lr = trial.suggest_float(\"learning_rate\", 0.00001, 0.001, log=True)\n",
    "        filter_0 = 32\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filter_0, Conv2D_kernel_size, strides=Conv2D_stride, activation=\"relu\", padding='same', input_shape=(224,224,1), kernel_initializer='he_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D(MaxPooling2D_kernel_size, strides=MaxPooling2D_stride, padding='same'))\n",
    "        \n",
    "        for i in range(n_conv_layers):\n",
    "            filters = trial.suggest_categorical(f\"filters{i}\", self.params.filters)\n",
    "            model.add(Conv2D(filters, Conv2D_kernel_size, strides=Conv2D_stride, activation=\"relu\", padding='same'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D(MaxPooling2D_kernel_size, strides=MaxPooling2D_stride, padding='same'))\n",
    "            \n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        \n",
    "        for i in range(n_dense_layers):\n",
    "            dense_units = trial.suggest_categorical(f\"dense_units{i}\",self.params.dense_units)\n",
    "            model.add(Dense(dense_units, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        # \n",
    "        # Allfilters = []\n",
    "        # \n",
    "        # # Add filter_0 manually if needed\n",
    "        # filter_0 = 32\n",
    "        # Allfilters.append(filter_0)\n",
    "        # \n",
    "        # if n_conv_layers == 6:\n",
    "        #    filter6_1 = trial.suggest_categorical(\"filter6_1\", [32, 64])\n",
    "        #    filter6_2= 64\n",
    "        #    filter6_3= trial.suggest_categorical(\"filter6_3\", [64, 128])\n",
    "        #    filter6_4= 128\n",
    "        #    filter6_5 = 512\n",
    "        #    Allfilters += [filter6_1, filter6_2, filter6_3, filter6_4, filter6_5]\n",
    "        # \n",
    "        # elif n_conv_layers == 5:\n",
    "        #    filter5_1 = trial.suggest_categorical(\"filter5_1\", [32, 64])\n",
    "        #    filter5_2 = trial.suggest_categorical(\"filter5_2\", [64, 128])\n",
    "        #    filter5_3 = trial.suggest_categorical(\"filter5_3\", [128, 512])\n",
    "        #    filter5_4 = 512\n",
    "        #    Allfilters += [filter5_1, filter5_2, filter5_3, filter5_4]\n",
    "        # \n",
    "        # elif n_conv_layers == 4:\n",
    "        #   filter4_1 = trial.suggest_categorical(\"filter4_1\", [32, 64])\n",
    "        #   filter4_2 = 64\n",
    "        #   filter4_3 = trial.suggest_categorical(\"filter4_3\", [128, 512])\n",
    "        #   Allfilters += [filter4_1, filter4_2, filter4_3]\n",
    "        # \n",
    "        # else:\n",
    "        #   filter3_1 = trial.suggest_categorical(\"filter3_1\", [32, 64])\n",
    "        #   filter3_2 = trial.suggest_categorical(\"filter3_2\", [64, 128])\n",
    "        #   Allfilters += [filter3_1, filter3_2]\n",
    "        # \n",
    "        # \n",
    "        # model = Sequential()\n",
    "        # \n",
    "        # \n",
    "        #  # First layer with input shape\n",
    "        # model.add(Conv2D(Allfilters[0],Conv2D_kernel_size, strides=Conv2D_stride, activation='relu', padding='same', input_shape=(224, 224, 1)))\n",
    "        # model.add(BatchNormalization())\n",
    "        # model.add(MaxPooling2D(MaxPooling2D_kernel_size, strides=MaxPooling2D_stride, padding='same'))\n",
    "        # \n",
    "        # # Remaining conv layers\n",
    "        # for i in range(1, n_conv_layers):\n",
    "        #      model.add(Conv2D(Allfilters[i],Conv2D_kernel_size, strides=Conv2D_stride, activation='relu', padding='same'))\n",
    "        #      model.add(BatchNormalization())\n",
    "        #      model.add(MaxPooling2D(MaxPooling2D_kernel_size, strides=MaxPooling2D_stride, padding='same'))\n",
    "        #             \n",
    "        # model.add(GlobalAveragePooling2D()) \n",
    "        # \n",
    "        # \n",
    "        # \n",
    "        # Alldenseunits = []\n",
    "        # \n",
    "        # if n_dense_layers == 5:\n",
    "        #    dense_units5_1 = trial.suggest_categorical(\"dense_units5_1\", [256, 128])\n",
    "        #    dense_units5_2 = trial.suggest_categorical(\"dense_units5_2\", [128, 64])\n",
    "        #    dense_units5_3 = trial.suggest_categorical(\"dense_units5_3\", [64, 32])\n",
    "        #    dense_units5_4 = trial.suggest_categorical(\"dense_units5_4\", [32, 10])\n",
    "        #    Alldenseunits = [dense_units5_1, dense_units5_2, dense_units5_3, dense_units5_4]\n",
    "        # \n",
    "        # elif n_dense_layers == 4:\n",
    "        #    dense_units4_1 = trial.suggest_categorical(\"dense_units4_1\", [256, 128])\n",
    "        #    dense_units4_2 = trial.suggest_categorical(\"dense_units4_2\", [128, 64])\n",
    "        #    dense_units4_3 = trial.suggest_categorical(\"dense_units4_3\", [64, 32])\n",
    "        #    Alldenseunits = [dense_units4_1, dense_units4_2, dense_units4_3]\n",
    "        # \n",
    "        # elif n_dense_layers == 3:\n",
    "        #    dense_units3_1 = trial.suggest_categorical(\"dense_units3_1\", [128, 64])\n",
    "        #    dense_units3_2 = trial.suggest_categorical(\"dense_units3_2\", [64, 32])\n",
    "        #    Alldenseunits = [dense_units3_1, dense_units3_2]\n",
    "        # \n",
    "        # else:\n",
    "        #    dense_units2_1 = trial.suggest_categorical(\"dense_units2_1\", [32, 64])\n",
    "        #    Alldenseunits = [dense_units2_1]\n",
    "        # \n",
    "        # for units in Alldenseunits:\n",
    "        #    model.add(Dense(units, activation='relu'))\n",
    "        #    model.add(BatchNormalization())\n",
    "        #    model.add(Dropout(0.3))\n",
    "        # \n",
    "        # model.add(Dense(4, activation='softmax')) \n",
    "\n",
    "\n",
    "            # Optimizer\n",
    "        if optimizer_name == 'adam':\n",
    "            optimizer = Adam(learning_rate=lr)\n",
    "        elif optimizer_name == 'sgd':\n",
    "            optimizer = SGD(learning_rate=lr, momentum= 0.9, nesterov=True)\n",
    "        elif optimizer_name == \"RMSprop\":\n",
    "            optimizer = RMSprop(learning_rate=lr, rho=0.9, momentum=0.0, epsilon=1e-07, clipvalue=1.0)\n",
    "        else:\n",
    "             raise ValueError(\"Choose 'adam' ,'sgd' or 'RMSprop' for optimizer_name\")\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                  loss=self.params.loss,\n",
    "                  metrics=self.params.metrics)\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        dagshub.init(repo_owner='DikshantPatel2210', repo_name='KidneyDiseaseClassification-DLProject', mlflow=True)\n",
    "        mlflow.set_tracking_uri(\"https://dagshub.com/DikshantPatel2210/KidneyDiseaseClassification-DLProject.mlflow\")\n",
    "        mlflow.set_experiment(\"CNN_Optuna_MLFLOW\")\n",
    "        try:\n",
    "            if mlflow.active_run():\n",
    "               mlflow.end_run()\n",
    "\n",
    "            input_example = np.random.rand(32, 224, 224, 1).astype(float)\n",
    "            output_example = np.random.rand(32, 4).astype(float)\n",
    "\n",
    "            with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "                n_conv_layers = trial.suggest_int(\"n_conv_layers\", 3, 6)\n",
    "                n_dense_layers = trial.suggest_int(\"n_dense_layers\", 2, 5)\n",
    "                model = self.create_model(trial)\n",
    "\n",
    "                # Log hyperparameters\n",
    "                for param_name, param_value in trial.params.items():\n",
    "                    mlflow.log_param(param_name, param_value)\n",
    "\n",
    "                history = model.fit(\n",
    "                    self.training_set,\n",
    "                    steps_per_epoch=len(self.train_df) // 32,\n",
    "                    validation_data=self.validation_set,\n",
    "                    epochs=self.params.epochs,\n",
    "                    #callbacks =[tf.keras.callbacks.EarlyStopping(patience=20, min_delta=0.001, baseline=0.99,  \n",
    "                    #                                             monitor=\"val_accuracy\", mode=\"max\", verbose=1, restore_best_weights=True),\n",
    "                    #           tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6, cooldown=2, \n",
    "                    #                                                 min_delta=0.001, monitor=\"val_loss\", mode=\"min\", verbose=1),\n",
    "                    #            tf.keras.callbacks.ModelCheckpoint(monitor=\"val_accuracy\", mode=\"max\", \n",
    "                    #                                               filepath=\"artifacts/checkpoints/best_model.keras\", save_best_only=True, verbose=1, save_weights_only=False)],\n",
    "                    callbacks=self.callbacks,\n",
    "                    class_weight=self.class_weights_dict,\n",
    "                    verbose=1\n",
    "                )\n",
    "\n",
    "                # Static params\n",
    "                mlflow.log_param(\"image_size\", \"224x224x1\")\n",
    "                mlflow.log_param(\"filter_0\", 32)\n",
    "                mlflow.log_param(\"last_dense_units\", 4)\n",
    "                mlflow.log_param(\"Batchsize\", 32)\n",
    "                mlflow.log_param(\"loss function\", \"categorical_crossentropy\")\n",
    "                \n",
    "                if n_conv_layers == 6:\n",
    "                    mlflow.log_param(\"filter6_2\", 64)\n",
    "                    mlflow.log_param(\"filter6_4\", 128)\n",
    "                    mlflow.log_param(\"filter6_5\", 512)\n",
    "                if n_conv_layers == 5:\n",
    "                    mlflow.log_param(\"filter5_4\", 512)\n",
    "                if n_conv_layers == 4:\n",
    "                    mlflow.log_param(\"filter4_2\", 64)\n",
    "                 \n",
    "                mlflow.log_param(f\"dense_units{n_dense_layers}_{n_dense_layers}\", 4)   \n",
    "            \n",
    "            \n",
    "                if np.any(np.isnan(history.history['loss'])) or np.any(np.isnan(history.history['val_loss'])):\n",
    "                    raise ValueError(\"NaN value encountered in loss or validation loss.\")\n",
    "                \n",
    "                \n",
    "                # Log the metrics (train and validation accuracy, loss)\n",
    "                train_accuracy = max(history.history['accuracy'])  # or 'acc', depending on your Keras version\n",
    "                train_loss = min(history.history['loss'])\n",
    "                val_accuracy = max(history.history['val_accuracy'])\n",
    "                val_loss = min(history.history['val_loss'])\n",
    "                \n",
    "                loss_train = history.history['loss'][-1]\n",
    "                loss_val = history.history['val_loss'][-1]\n",
    "                acc_val = history.history['val_accuracy'][-1]\n",
    "                loss_diff = abs(loss_train - loss_val)\n",
    "                objective_value = acc_val - loss_diff\n",
    "           # Log metrics to MLflow\n",
    "                mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "                mlflow.log_metric(\"train_loss\", train_loss)\n",
    "                mlflow.log_metric(\"val_accuracy\", val_accuracy)\n",
    "                mlflow.log_metric(\"val_loss\", val_loss)\n",
    "                mlflow.log_metric(\"acc_val - loss_diff\", objective_value)\n",
    "\n",
    "                # Log model\n",
    "                signature = infer_signature(input_example, output_example)\n",
    "                mlflow.tensorflow.log_model(model, artifact_path=\"model\", signature=signature)\n",
    "\n",
    "                return objective_value\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Trial Failed] Error: {e}\")\n",
    "            mlflow.log_param(\"failed_trial\", True)\n",
    "            mlflow.log_param(\"error_msg\", str(e)[:500])\n",
    "            return float(\"nan\")\n",
    "\n",
    "        finally:\n",
    "            mlflow.end_run()\n",
    "            try:\n",
    "                del model\n",
    "            except:\n",
    "                pass\n",
    "            K.clear_session()\n",
    "            gc.collect()"
   ],
   "id": "f34200e2b6d07185",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T09:30:35.175942Z",
     "start_time": "2025-05-13T09:26:02.709465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from cnnClassifier.config.configuration import ConfigurationManager\n",
    "from cnnClassifier.components.data_loader import DataLoader\n",
    "from cnnClassifier.components.callback import CallbackHandler\n",
    "\n",
    "\n",
    "import optuna\n",
    "\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "\n",
    "    # Load data\n",
    "    data_loader_config = config.get_data_loader_config()\n",
    "    data_loader = DataLoader(config=data_loader_config)\n",
    "    train_generator, val_generator, test_generator,train_df, ori_train = data_loader.get_generators()\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks_config = config.get_callbacks_config()\n",
    "    handler = CallbackHandler(config=callbacks_config, ori_training_set=ori_train)\n",
    "    class_weights = handler.get_class_weights()\n",
    "    callbacks = handler.get_callbacks()\n",
    "\n",
    "    # Optuna Config\n",
    "    optuna_config = config.get_Optuna_config()\n",
    "\n",
    "    # Optuna Tuner\n",
    "    optuna_tunner = OptunaModelTunner11(\n",
    "        params=optuna_config,\n",
    "        training_set=train_generator,\n",
    "        validation_set=val_generator,\n",
    "        train_df=train_df,\n",
    "        callbacks=callbacks,\n",
    "        class_weights_dict=class_weights,\n",
    "        class_names=list(ori_train.class_indices.keys())\n",
    "    )\n",
    "\n",
    "    # Run Optuna Study\n",
    "    study = optuna.create_study(direction=\"maximize\",\n",
    "                                sampler=optuna.samplers.TPESampler(),\n",
    "                                study_name=\"kidney_optuna_study\",\n",
    "                                storage=\"sqlite:///optuna_study.db\",  # this saves to file\n",
    "                                load_if_exists=True )\n",
    "    study.optimize(optuna_tunner.objective, n_trials=30)\n",
    "\n",
    "    \n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    raise e\n",
    "\n"
   ],
   "id": "3eca916ebd5bad40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:02,729: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-05-13 11:26:02,745: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2025-05-13 11:26:02,746: INFO: common: created directory at: artifacts]\n",
      "[2025-05-13 11:26:02,747: INFO: data_loader: Loading dataframe from file: artifacts/data_split/train.csv]\n",
      "[2025-05-13 11:26:02,772: INFO: data_loader: Dataframe loaded successfully with 8712 records.]\n",
      "[2025-05-13 11:26:02,773: INFO: data_loader: Loading dataframe from file: artifacts/data_split/val.csv]\n",
      "[2025-05-13 11:26:02,781: INFO: data_loader: Dataframe loaded successfully with 1121 records.]\n",
      "[2025-05-13 11:26:02,782: INFO: data_loader: Loading dataframe from file: artifacts/data_split/test.csv]\n",
      "[2025-05-13 11:26:02,792: INFO: data_loader: Dataframe loaded successfully with 2613 records.]\n",
      "[2025-05-13 11:26:03,333: INFO: data_loader: Valid file paths count: 8712]\n",
      "[2025-05-13 11:26:03,457: INFO: data_loader: Valid file paths count: 1121]\n",
      "[2025-05-13 11:26:03,589: INFO: data_loader: Valid file paths count: 2613]\n",
      "[2025-05-13 11:26:03,597: INFO: data_loader: Generators created successfully.]\n",
      "Found 8712 validated image filenames belonging to 4 classes.\n",
      "Found 8712 validated image filenames belonging to 4 classes.\n",
      "Found 1121 validated image filenames belonging to 4 classes.\n",
      "Found 2613 validated image filenames belonging to 4 classes.\n",
      "[2025-05-13 11:26:05,218: INFO: data_loader: lengh of train_df: 8712 & Steps per epoch for training: 272]\n",
      "[2025-05-13 11:26:05,220: INFO: data_loader: Successfully created train<generator object DataLoader.combined_generator at 0x000001F7AC25E3C0>, validation<keras.preprocessing.image.DataFrameIterator object at 0x000001F88F7DDD90>, and test<keras.preprocessing.image.DataFrameIterator object at 0x000001F88F7DD5E0> generators.]\n",
      "[2025-05-13 11:26:05,221: INFO: common: created directory at: artifacts/checkpoints]\n",
      "[2025-05-13 11:26:05,222: INFO: callback: Computing class weights...]\n",
      "[2025-05-13 11:26:05,227: INFO: callback: Class Weights: {0: 0.6128306133933596, 1: 0.8389830508474576, 2: 1.362953692115144, 3: 2.259336099585062}]\n",
      "[2025-05-13 11:26:05,228: INFO: callback: Preparing callbacks...]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 11:26:05,230] A new study created in memory with name: no-name-9d552bc0-4a4a-4c7a-92ca-23d6561036e2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:05,467: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/DikshantPatel2210/KidneyDiseaseClassification-DLProject \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:05,474: INFO: helpers: Initialized MLflow to track repo \"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:05,477: INFO: helpers: Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!]\n",
      "Epoch 1/3\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 1.8684 - accuracy: 0.3542[2025-05-13 11:26:16,989: WARNING: callbacks: Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0704s vs `on_train_batch_end` time: 0.1204s). Check your callbacks.]\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.8390 - accuracy: 0.3398[2025-05-13 11:26:21,958: INFO: callback: [Epoch 001] Custom Objective = -0.084844,\n",
      " Train Acc = 0.3398, Train Loss = 1.8390, Val Acc = 0.3747, Val Loss = 1.3795]\n",
      "\n",
      "Epoch 00001: val_objective improved from -inf to -0.08484, saving model to artifacts/optuna_best_model\\best_model.keras\n",
      "8/8 [==============================] - 9s 865ms/step - loss: 1.8390 - accuracy: 0.3398 - val_loss: 1.3795 - val_accuracy: 0.3747 - val_objective: -0.0848 - lr: 3.7411e-04\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.3501 - accuracy: 0.4258[2025-05-13 11:26:27,472: INFO: callback: [Epoch 002] Custom Objective = 0.387438,\n",
      " Train Acc = 0.4258, Train Loss = 1.3501, Val Acc = 0.4077, Val Loss = 1.3704]\n",
      "\n",
      "Epoch 00002: val_objective improved from -0.08484 to 0.38744, saving model to artifacts/optuna_best_model\\best_model.keras\n",
      "8/8 [==============================] - 5s 758ms/step - loss: 1.3501 - accuracy: 0.4258 - val_loss: 1.3704 - val_accuracy: 0.4077 - val_objective: 0.3874 - lr: 3.7411e-04\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.3258 - accuracy: 0.4727[2025-05-13 11:26:33,082: INFO: callback: [Epoch 003] Custom Objective = 0.369704,\n",
      " Train Acc = 0.4727, Train Loss = 1.3258, Val Acc = 0.4077, Val Loss = 1.3638]\n",
      "\n",
      "Epoch 00003: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 6s 761ms/step - loss: 1.3258 - accuracy: 0.4727 - val_loss: 1.3638 - val_accuracy: 0.4077 - val_objective: 0.3697 - lr: 3.7411e-04\n",
      "[2025-05-13 11:26:39,537: INFO: builder_impl: Assets written to: C:\\Users\\DIKSHA~1\\AppData\\Local\\Temp\\tmpx3uy3g2s\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 11:26:56,132] Trial 0 finished with value: 0.3697035610675812 and parameters: {'n_conv_layers': 6, 'n_dense_layers': 2, 'optimizer': 'sgd', 'Conv2D_strides_size': '1x1', 'Conv2D_kernel_size': '3x3', 'MaxPooling2D_strides_size': '2x2', 'MaxPooling2D_kernel_size': '2x2', 'learning_rate': 0.00037410574902432017, 'filters0': 128, 'filters1': 128, 'filters2': 64, 'filters3': 128, 'filters4': 128, 'filters5': 64, 'dense_units0': 64, 'dense_units1': 512}. Best is trial 0 with value: 0.3697035610675812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:56,383: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/DikshantPatel2210/KidneyDiseaseClassification-DLProject \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:56,388: INFO: helpers: Initialized MLflow to track repo \"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:26:56,391: INFO: helpers: Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!]\n",
      "Epoch 1/3\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 1.9386 - accuracy: 0.2344[2025-05-13 11:27:11,279: WARNING: callbacks: Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0672s vs `on_train_batch_end` time: 0.1131s). Check your callbacks.]\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.0886 - accuracy: 0.2188[2025-05-13 11:27:15,929: INFO: callback: [Epoch 001] Custom Objective = -0.582896,\n",
      " Train Acc = 0.2188, Train Loss = 2.0886, Val Acc = 0.1106, Val Loss = 1.3951]\n",
      "\n",
      "Epoch 00001: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 8s 808ms/step - loss: 2.0886 - accuracy: 0.2188 - val_loss: 1.3951 - val_accuracy: 0.1106 - val_objective: -0.5829 - lr: 2.9377e-05\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.7924 - accuracy: 0.2695[2025-05-13 11:27:21,298: INFO: callback: [Epoch 002] Custom Objective = -0.280565,\n",
      " Train Acc = 0.2695, Train Loss = 1.7924, Val Acc = 0.1106, Val Loss = 1.4012]\n",
      "\n",
      "Epoch 00002: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 5s 734ms/step - loss: 1.7924 - accuracy: 0.2695 - val_loss: 1.4012 - val_accuracy: 0.1106 - val_objective: -0.2806 - lr: 2.9377e-05\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.7672 - accuracy: 0.3086[2025-05-13 11:27:26,670: INFO: callback: [Epoch 003] Custom Objective = -0.248772,\n",
      " Train Acc = 0.3086, Train Loss = 1.7672, Val Acc = 0.1106, Val Loss = 1.4078]\n",
      "\n",
      "Epoch 00003: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 5s 740ms/step - loss: 1.7672 - accuracy: 0.3086 - val_loss: 1.4078 - val_accuracy: 0.1106 - val_objective: -0.2488 - lr: 2.9377e-05\n",
      "[2025-05-13 11:27:31,697: INFO: builder_impl: Assets written to: C:\\Users\\DIKSHA~1\\AppData\\Local\\Temp\\tmp6gmq13gw\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 11:27:47,442] Trial 1 finished with value: -0.24877247214317322 and parameters: {'n_conv_layers': 3, 'n_dense_layers': 4, 'optimizer': 'sgd', 'Conv2D_strides_size': '1x1', 'Conv2D_kernel_size': '3x3', 'MaxPooling2D_strides_size': '2x2', 'MaxPooling2D_kernel_size': '2x2', 'learning_rate': 2.93772797393864e-05, 'filters0': 32, 'filters1': 512, 'filters2': 64, 'dense_units0': 64, 'dense_units1': 512, 'dense_units2': 128, 'dense_units3': 32}. Best is trial 0 with value: 0.3697035610675812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:27:47,675: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/DikshantPatel2210/KidneyDiseaseClassification-DLProject \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:27:47,679: INFO: helpers: Initialized MLflow to track repo \"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:27:47,681: INFO: helpers: Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!]\n",
      "Epoch 1/3\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 2.0138 - accuracy: 0.2969[2025-05-13 11:28:07,902: WARNING: callbacks: Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1042s vs `on_train_batch_end` time: 0.1858s). Check your callbacks.]\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.9213 - accuracy: 0.3047[2025-05-13 11:28:12,803: INFO: callback: [Epoch 001] Custom Objective = -0.259774,\n",
      " Train Acc = 0.3047, Train Loss = 1.9213, Val Acc = 0.2979, Val Loss = 1.3635]\n",
      "\n",
      "Epoch 00001: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 12s 923ms/step - loss: 1.9213 - accuracy: 0.3047 - val_loss: 1.3635 - val_accuracy: 0.2979 - val_objective: -0.2598 - lr: 9.8164e-04\n",
      "Epoch 2/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.5515 - accuracy: 0.4023[2025-05-13 11:28:19,067: INFO: callback: [Epoch 002] Custom Objective = 0.062646,\n",
      " Train Acc = 0.4023, Train Loss = 1.5515, Val Acc = 0.2801, Val Loss = 1.3340]\n",
      "\n",
      "Epoch 00002: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 6s 845ms/step - loss: 1.5515 - accuracy: 0.4023 - val_loss: 1.3340 - val_accuracy: 0.2801 - val_objective: 0.0626 - lr: 9.8164e-04\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.5230 - accuracy: 0.4766[2025-05-13 11:28:25,477: INFO: callback: [Epoch 003] Custom Objective = 0.100978,\n",
      " Train Acc = 0.4766, Train Loss = 1.5230, Val Acc = 0.2756, Val Loss = 1.3483]\n",
      "\n",
      "Epoch 00003: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 6s 872ms/step - loss: 1.5230 - accuracy: 0.4766 - val_loss: 1.3483 - val_accuracy: 0.2756 - val_objective: 0.1010 - lr: 9.8164e-04\n",
      "[2025-05-13 11:28:32,567: INFO: builder_impl: Assets written to: C:\\Users\\DIKSHA~1\\AppData\\Local\\Temp\\tmpsxmi9yx0\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 11:28:52,743] Trial 2 finished with value: 0.1009780764579773 and parameters: {'n_conv_layers': 6, 'n_dense_layers': 3, 'optimizer': 'adam', 'Conv2D_strides_size': '1x1', 'Conv2D_kernel_size': '3x3', 'MaxPooling2D_strides_size': '2x2', 'MaxPooling2D_kernel_size': '2x2', 'learning_rate': 0.000981637252508175, 'filters0': 128, 'filters1': 512, 'filters2': 128, 'filters3': 512, 'filters4': 64, 'filters5': 128, 'dense_units0': 32, 'dense_units1': 512, 'dense_units2': 64}. Best is trial 0 with value: 0.3697035610675812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:28:52,948: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/DikshantPatel2210/KidneyDiseaseClassification-DLProject \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:28:52,951: INFO: helpers: Initialized MLflow to track repo \"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:28:52,953: INFO: helpers: Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!]\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.1316 - accuracy: 0.2227[2025-05-13 11:29:09,303: INFO: callback: [Epoch 001] Custom Objective = -0.630719,\n",
      " Train Acc = 0.2227, Train Loss = 2.1316, Val Acc = 0.1115, Val Loss = 1.3894]\n",
      "\n",
      "Epoch 00001: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 8s 939ms/step - loss: 2.1316 - accuracy: 0.2227 - val_loss: 1.3894 - val_accuracy: 0.1115 - val_objective: -0.6307 - lr: 1.1552e-04\n",
      "Epoch 2/3\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.0505 - accuracy: 0.2232[2025-05-13 11:29:13,330: INFO: callback: [Epoch 002] Custom Objective = -0.487511,\n",
      " Train Acc = 0.2344, Train Loss = 1.9937, Val Acc = 0.1106, Val Loss = 1.3956]\n",
      "\n",
      "Epoch 00002: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 4s 565ms/step - loss: 1.9937 - accuracy: 0.2344 - val_loss: 1.3956 - val_accuracy: 0.1106 - val_objective: -0.4875 - lr: 1.1552e-04\n",
      "Epoch 3/3\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 2.1853 - accuracy: 0.2143[2025-05-13 11:29:17,420: INFO: callback: [Epoch 003] Custom Objective = -0.573692,\n",
      " Train Acc = 0.2227, Train Loss = 2.0875, Val Acc = 0.1106, Val Loss = 1.4032]\n",
      "\n",
      "Epoch 00003: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 4s 579ms/step - loss: 2.0875 - accuracy: 0.2227 - val_loss: 1.4032 - val_accuracy: 0.1106 - val_objective: -0.5737 - lr: 1.1552e-04\n",
      "[2025-05-13 11:29:22,568: INFO: builder_impl: Assets written to: C:\\Users\\DIKSHA~1\\AppData\\Local\\Temp\\tmpzacjldmz\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 11:29:38,239] Trial 3 finished with value: -0.5736924111843109 and parameters: {'n_conv_layers': 4, 'n_dense_layers': 3, 'optimizer': 'adam', 'Conv2D_strides_size': '2x2', 'Conv2D_kernel_size': '3x3', 'MaxPooling2D_strides_size': '2x2', 'MaxPooling2D_kernel_size': '2x2', 'learning_rate': 0.00011552265809826987, 'filters0': 128, 'filters1': 128, 'filters2': 32, 'filters3': 128, 'dense_units0': 32, 'dense_units1': 32, 'dense_units2': 64}. Best is trial 0 with value: 0.3697035610675812.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:29:38,455: INFO: _client: HTTP Request: GET https://dagshub.com/api/v1/repos/DikshantPatel2210/KidneyDiseaseClassification-DLProject \"HTTP/1.1 200 OK\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:29:38,460: INFO: helpers: Initialized MLflow to track repo \"DikshantPatel2210/KidneyDiseaseClassification-DLProject\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-13 11:29:38,462: INFO: helpers: Repository DikshantPatel2210/KidneyDiseaseClassification-DLProject initialized!]\n",
      "Epoch 1/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.7887 - accuracy: 0.3164[2025-05-13 11:29:57,790: INFO: callback: [Epoch 001] Custom Objective = 0.005676,\n",
      " Train Acc = 0.3164, Train Loss = 1.7887, Val Acc = 0.4077, Val Loss = 1.3867]\n",
      "\n",
      "Epoch 00001: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 7s 839ms/step - loss: 1.7887 - accuracy: 0.3164 - val_loss: 1.3867 - val_accuracy: 0.4077 - val_objective: 0.0057 - lr: 6.1821e-04\n",
      "Epoch 2/3\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 1.6567 - accuracy: 0.3527[2025-05-13 11:30:02,046: INFO: callback: [Epoch 002] Custom Objective = 0.195316,\n",
      " Train Acc = 0.3633, Train Loss = 1.5988, Val Acc = 0.4077, Val Loss = 1.3864]\n",
      "\n",
      "Epoch 00002: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 4s 594ms/step - loss: 1.5988 - accuracy: 0.3633 - val_loss: 1.3864 - val_accuracy: 0.4077 - val_objective: 0.1953 - lr: 6.1821e-04\n",
      "Epoch 3/3\n",
      "8/8 [==============================] - ETA: 0s - loss: 1.3072 - accuracy: 0.4258[2025-05-13 11:30:06,774: INFO: callback: [Epoch 003] Custom Objective = 0.330662,\n",
      " Train Acc = 0.4258, Train Loss = 1.3072, Val Acc = 0.4077, Val Loss = 1.3842]\n",
      "\n",
      "Epoch 00003: val_objective did not improve from 0.38744\n",
      "8/8 [==============================] - 5s 669ms/step - loss: 1.3072 - accuracy: 0.4258 - val_loss: 1.3842 - val_accuracy: 0.4077 - val_objective: 0.3307 - lr: 6.1821e-04\n",
      "[2025-05-13 11:30:13,334: INFO: builder_impl: Assets written to: C:\\Users\\DIKSHA~1\\AppData\\Local\\Temp\\tmp7e5vyq5p\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-13 11:30:35,161] Trial 4 finished with value: 0.3306620419025421 and parameters: {'n_conv_layers': 6, 'n_dense_layers': 2, 'optimizer': 'sgd', 'Conv2D_strides_size': '2x2', 'Conv2D_kernel_size': '3x3', 'MaxPooling2D_strides_size': '2x2', 'MaxPooling2D_kernel_size': '2x2', 'learning_rate': 0.0006182110838061356, 'filters0': 128, 'filters1': 128, 'filters2': 64, 'filters3': 64, 'filters4': 512, 'filters5': 512, 'dense_units0': 32, 'dense_units1': 512}. Best is trial 0 with value: 0.3697035610675812.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bd969fea8d051664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c05d208872324464"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c6afd1e172163fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "825bb42313127ae0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2da30147128acd97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "171c77e2fd0c922c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T18:10:47.174376Z",
     "start_time": "2025-05-12T18:10:47.160930Z"
    }
   },
   "cell_type": "code",
   "source": [
    " class OptunaModelTunnerSimple:\n",
    "    def __init__(self, training_set, validation_set, train_df, class_weights_dict, class_names, callbacks):\n",
    "        self.training_set = training_set\n",
    "        self.validation_set = validation_set\n",
    "        self.train_df = train_df\n",
    "        self.class_weights_dict = class_weights_dict\n",
    "        self.class_names = class_names\n",
    "        self.callbacks = callbacks\n",
    "    def create_model(self, trial):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(224, 224, 1)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "        for i in range(trial.suggest_int(\"n_conv\", 1, 3)):\n",
    "            filters = trial.suggest_categorical(f\"filters_{i}\", [32, 64, 128])\n",
    "            model.add(Conv2D(filters, (3, 3), activation=\"relu\", padding=\"same\"))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "\n",
    "        for i in range(trial.suggest_int(\"n_dense\", 1, 2)):\n",
    "            units = trial.suggest_categorical(f\"dense_units_{i}\", [64, 128, 256])\n",
    "            model.add(Dense(units, activation=\"relu\"))\n",
    "            model.add(Dropout(0.3))\n",
    "\n",
    "        model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "        optimizer_choice = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"RMSprop\"])\n",
    "        lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "        if optimizer_choice == \"adam\":\n",
    "            optimizer = Adam(learning_rate=lr)\n",
    "        elif optimizer_choice == \"sgd\":\n",
    "            optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
    "        else:\n",
    "            optimizer = RMSprop(learning_rate=lr)\n",
    "\n",
    "        model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        return model\n",
    "\n",
    "    def objective(self, trial):\n",
    "        dagshub.init(repo_owner='DikshantPatel2210', repo_name='KidneyDiseaseClassification-DLProject', mlflow=True)\n",
    "        mlflow.set_tracking_uri(\"https://dagshub.com/DikshantPatel2210/KidneyDiseaseClassification-DLProject.mlflow\")\n",
    "        mlflow.set_experiment(\"CNN_Optuna_MLFLOW\")\n",
    "\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "            model = self.create_model(trial)\n",
    "\n",
    "            mlflow.log_params(trial.params)\n",
    "            mlflow.log_param(\"batch_size\", 32)\n",
    "\n",
    "            history = model.fit(\n",
    "                self.training_set,\n",
    "                steps_per_epoch=len(self.train_df) // 32,\n",
    "                validation_data=self.validation_set,\n",
    "                epochs=5,\n",
    "                callbacks= self.callbacks,\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            val_acc = max(history.history[\"val_accuracy\"])\n",
    "            train_loss = min(history.history[\"loss\"])\n",
    "            val_loss = min(history.history[\"val_loss\"])\n",
    "            score = val_acc - abs(train_loss - val_loss)\n",
    "\n",
    "            mlflow.log_metrics({\n",
    "                \"train_accuracy\": max(history.history[\"accuracy\"]),\n",
    "                \"val_accuracy\": val_acc,\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"score\": score\n",
    "            })\n",
    "\n",
    "            # Log model\n",
    "            input_example = np.random.rand(1, 224, 224, 1).astype(np.float32)\n",
    "            output_example = model.predict(input_example)\n",
    "            mlflow.tensorflow.log_model(model, \"model\", signature=infer_signature(input_example, output_example))\n",
    "\n",
    "            K.clear_session()\n",
    "            del model\n",
    "            gc.collect()\n",
    "\n",
    "            return score"
   ],
   "id": "e402619673a4748c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 12,
   "source": [
    "class OptunaModelTunner12:\n",
    "    def __init__(self,params: OptunaConfig, training_set, validation_set, train_df, callbacks, class_weights_dict, class_names):\n",
    "        self.params = params\n",
    "        self.training_set = training_set\n",
    "        self.validation_set = validation_set\n",
    "        self.train_df = train_df\n",
    "        self.callbacks = callbacks\n",
    "        self.class_weights_dict = class_weights_dict\n",
    "        self.class_names = class_names\n",
    "        \n",
    "    def create_model(self, trial):\n",
    "        \n",
    "        n_conv_layers = trial.suggest_int(\"n_conv_layers\", self.params.min_n_conv_layers, self.params.max_n_conv_layers)\n",
    "        n_dense_layers = trial.suggest_int(\"n_dense_layers\", self.params.min_n_dense_layers, self.params.max_n_dense_layers)\n",
    "        optimizer_name = trial.suggest_categorical('optimizer', self.params.optimizer)\n",
    "        #strides_size = trial.suggest_categorical(\"strides_size\", self.params.strides_size)\n",
    "        #filters = trial.suggest_categorical(\"filters\", self.params.filters)\n",
    "        #dense_units = trial.suggest_categorical(\"dense_units\", self.params.dense_units)\n",
    "        #lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3,3), strides=(2, 2), activation=\"relu\", padding='same', input_shape=(224,224,1), kernel_initializer='he_normal'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "        \n",
    "        for i in range(n_conv_layers):\n",
    "            filters = trial.suggest_categorical(f\"filters{i}\", self.params.filters)\n",
    "            model.add(Conv2D(filters, (3,3), strides=(2, 2), activation=\"relu\", padding='same'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "            \n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        \n",
    "        for i in range(n_dense_layers):\n",
    "            dense_units = trial.suggest_categorical(f\"dense_units{i}\",self.params.dense_units)\n",
    "            model.add(Dense(dense_units, activation='relu'))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Dropout(0.3))\n",
    "        \n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "        if optimizer_name == 'adam':\n",
    "             \n",
    "             optimizer = Adam(learning_rate=lr)\n",
    "        elif optimizer_name == 'sgd':\n",
    "             optimizer = SGD(learning_rate=lr)\n",
    "        elif optimizer_name == \"RMSprop\":\n",
    "             optimizer = RMSprop(learning_rate=lr)\n",
    "        else:\n",
    "             raise ValueError(\"Choose 'adam' ,'sgd' or 'RMSprop' for optimizer_name\")\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "        return model\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        dagshub.init(repo_owner='DikshantPatel2210', repo_name='KidneyDiseaseClassification-DLProject', mlflow=True)\n",
    "        mlflow.set_tracking_uri(\"https://dagshub.com/DikshantPatel2210/KidneyDiseaseClassification-DLProject.mlflow\")\n",
    "        mlflow.set_experiment(\"CNN_Optuna_MLFLOW\")\n",
    "        try:\n",
    "            if mlflow.active_run():\n",
    "               mlflow.end_run()\n",
    "\n",
    "            input_example = np.random.rand(32, 224, 224, 1).astype(np.float32)\n",
    "            output_example = np.random.rand(32, 4).astype(np.float32)\n",
    "\n",
    "            with mlflow.start_run(run_name=f\"trial_{trial.number}\"):\n",
    "                model = self.create_model(trial)\n",
    "\n",
    "                # Log hyperparameters\n",
    "                for param_name, param_value in trial.params.items():\n",
    "                    mlflow.log_param(param_name, param_value)\n",
    "\n",
    "                history = model.fit(\n",
    "                    self.training_set,\n",
    "                    steps_per_epoch=len(self.train_df) // 32,\n",
    "                    validation_data=self.validation_set,\n",
    "                    epochs=30,\n",
    "                    callbacks=self.callbacks,\n",
    "                    class_weight=self.class_weights_dict,\n",
    "                    verbose=0\n",
    "                )\n",
    "\n",
    "                # Static params\n",
    "                mlflow.log_param(\"image_size\", \"224x224x1\")\n",
    "                mlflow.log_param(\"Batchsize\", 32)\n",
    "                mlflow.log_param(\"loss function\", \"categorical_crossentropy\")\n",
    "\n",
    "                acc_val = history.history['val_accuracy'][-1]\n",
    "                loss_train = history.history['loss'][-1]\n",
    "                loss_val = history.history['val_loss'][-1]\n",
    "                loss_diff = abs(loss_train - loss_val)\n",
    "                objective_value = acc_val - loss_diff\n",
    "\n",
    "                # Metrics\n",
    "                mlflow.log_metric(\"train_accuracy\", max(history.history['accuracy']))\n",
    "                mlflow.log_metric(\"train_loss\", min(history.history['loss']))\n",
    "                mlflow.log_metric(\"val_accuracy\", max(history.history['val_accuracy']))\n",
    "                mlflow.log_metric(\"val_loss\", min(history.history['val_loss']))\n",
    "                mlflow.log_metric(\"acc_val - loss_diff\", objective_value)\n",
    "\n",
    "                # Predictions\n",
    "             #   y_pred_probs = model.predict(self.validation_set)\n",
    "             #   y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "             #   y_true = self.validation_set.classes\n",
    "\n",
    "             #   report = classification_report(y_true, y_pred, target_names=self.class_names, output_dict=True)\n",
    "             #   df_report = pd.DataFrame(report).transpose()\n",
    "             #   report_path = f\"classification_report_trial_{trial.number}.csv\"\n",
    "             #   df_report.to_csv(report_path)\n",
    "            #   mlflow.log_artifact(report_path)\n",
    "\n",
    "                # Confusion Matrix\n",
    "            #    cm = confusion_matrix(y_true, y_pred)\n",
    "              #  fig, ax = plt.subplots(figsize=(8, 6))\n",
    "             #   sns.heatmap(cm, annot=True, fmt='d', xticklabels=self.class_names, yticklabels=self.class_names, cmap='Blues', ax=ax)\n",
    "             #   plt.xlabel('Predicted')\n",
    "             #   plt.ylabel('Actual')\n",
    "             #   plt.title('Confusion Matrix')\n",
    "             #   fig_path = f\"conf_matrix_trial_{trial.number}.png\"\n",
    "             #   fig.savefig(fig_path)\n",
    "             #   mlflow.log_artifact(fig_path)\n",
    "             #   plt.close(fig)\n",
    "\n",
    "                # Log model\n",
    "                signature = infer_signature(input_example, output_example)\n",
    "                mlflow.tensorflow.log_model(model, artifact_path=\"model\", signature=signature)\n",
    "\n",
    "                return objective_value\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Trial Failed] Error: {e}\")\n",
    "            mlflow.log_param(\"failed_trial\", True)\n",
    "            mlflow.log_param(\"error_msg\", str(e)[:500])\n",
    "            return float(\"nan\")\n",
    "\n",
    "        finally:\n",
    "            mlflow.end_run()\n",
    "            try:\n",
    "                del model\n",
    "            except:\n",
    "                pass\n",
    "            K.clear_session()\n",
    "            gc.collect()"
   ],
   "id": "65fdb5ba9ee60ecb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2f8e2aa5b10ba301"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d9b1bac7c341e653"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "836dec9a046bf5cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
